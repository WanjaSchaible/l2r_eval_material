
[+] General Parameters:
Training data:	/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/train_sts
Test data:	/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/test_sts
Feature vector representation: Dense.
Ranking method:	Random Forests
Feature description file:	Unspecified. All features will be used.
Train metric:	MAP
Test metric:	MAP
Feature normalization: No

[+] Random Forests's Parameters:
No. of bags: 300
Sub-sampling: 1.0
Feature-sampling: 0.3
No. of trees: 1
No. of leaves: 100
No. of threshold candidates: 256
Learning rate: 0.1


Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/train_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/train_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/train_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/train_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/train_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/train_sts]... [Done.]            
(149 ranked lists, 44700 entries read)

Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/test_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/test_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/test_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/test_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/test_sts]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ivan-herman.net/foldsSAME/test_sts]... [Done.]            
(149 ranked lists, 44700 entries read)
Initializing... [Done]
------------------------------------
Training starts...
------------------------------------
bag       | MAP-B     | MAP-OOB     | 
------------------------------------
b[1]      | 0.1767    | 
b[2]      | 0.4779    | 
b[3]      | 0.3752    | 
b[4]      | 0.3804    | 
b[5]      | 0.4066    | 
b[6]      | 0.4763    | 
b[7]      | 0.2544    | 
b[8]      | 0.4366    | 
b[9]      | 0.282     | 
b[10]     | 0.1957    | 
b[11]     | 0.4492    | 
b[12]     | 0.1947    | 
b[13]     | 0.4488    | 
b[14]     | 0.3238    | 
b[15]     | 0.318     | 
b[16]     | 0.2251    | 
b[17]     | 0.4385    | 
b[18]     | 0.4944    | 
b[19]     | 0.2194    | 
b[20]     | 0.4301    | 
b[21]     | 0.0609    | 
b[22]     | 0.2968    | 
b[23]     | 0.3321    | 
b[24]     | 0.3505    | 
b[25]     | 0.1682    | 
b[26]     | 0.3779    | 
b[27]     | 0.2727    | 
b[28]     | 0.3117    | 
b[29]     | 0.3511    | 
b[30]     | 0.4149    | 
b[31]     | 0.2527    | 
b[32]     | 0.4091    | 
b[33]     | 0.3641    | 
b[34]     | 0.3954    | 
b[35]     | 0.1529    | 
b[36]     | 0.3613    | 
b[37]     | 0.3398    | 
b[38]     | 0.5285    | 
b[39]     | 0.2009    | 
b[40]     | 0.3211    | 
b[41]     | 0.2602    | 
b[42]     | 0.3889    | 
b[43]     | 0.608     | 
b[44]     | 0.3436    | 
b[45]     | 0.3954    | 
b[46]     | 0.2757    | 
b[47]     | 0.2547    | 
b[48]     | 0.4749    | 
b[49]     | 0.4619    | 
b[50]     | 0.3065    | 
b[51]     | 0.2833    | 
b[52]     | 0.4625    | 
b[53]     | 0.2347    | 
b[54]     | 0.2997    | 
b[55]     | 0.2877    | 
b[56]     | 0.2443    | 
b[57]     | 0.2714    | 
b[58]     | 0.4376    | 
b[59]     | 0.4061    | 
b[60]     | 0.3321    | 
b[61]     | 0.2737    | 
b[62]     | 0.378     | 
b[63]     | 0.4427    | 
b[64]     | 0.1624    | 
b[65]     | 0.4288    | 
b[66]     | 0.4935    | 
b[67]     | 0.4134    | 
b[68]     | 0.5656    | 
b[69]     | 0.5467    | 
b[70]     | 0.4685    | 
b[71]     | 0.2908    | 
b[72]     | 0.0241    | 
b[73]     | 0.2709    | 
b[74]     | 0.1926    | 
b[75]     | 0.3932    | 
b[76]     | 0.4796    | 
b[77]     | 0.389     | 
b[78]     | 0.1536    | 
b[79]     | 0.3726    | 
b[80]     | 0.4459    | 
b[81]     | 0.2557    | 
b[82]     | 0.5019    | 
b[83]     | 0.0272    | 
b[84]     | 0.2811    | 
b[85]     | 0.2562    | 
b[86]     | 0.3368    | 
b[87]     | 0.0363    | 
b[88]     | 0.2       | 
b[89]     | 0.4041    | 
b[90]     | 0.3808    | 
b[91]     | 0.4865    | 
b[92]     | 0.4461    | 
b[93]     | 0.575     | 
b[94]     | 0.2975    | 
b[95]     | 0.2239    | 
b[96]     | 0.5274    | 
b[97]     | 0.4587    | 
b[98]     | 0.3709    | 
b[99]     | 0.3353    | 
b[100]    | 0.0622    | 
b[101]    | 0.2879    | 
b[102]    | 0.3495    | 
b[103]    | 0.1936    | 
b[104]    | 0.3612    | 
b[105]    | 0.2654    | 
b[106]    | 0.4711    | 
b[107]    | 0.1176    | 
b[108]    | 0.5903    | 
b[109]    | 0.3348    | 
b[110]    | 0.3299    | 
b[111]    | 0.4014    | 
b[112]    | 0.4121    | 
b[113]    | 0.4957    | 
b[114]    | 0.3062    | 
b[115]    | 0.4248    | 
b[116]    | 0.3244    | 
b[117]    | 0.0745    | 
b[118]    | 0.3702    | 
b[119]    | 0.475     | 
b[120]    | 0.2506    | 
b[121]    | 0.3874    | 
b[122]    | 0.3328    | 
b[123]    | 0.3845    | 
b[124]    | 0.2586    | 
b[125]    | 0.5098    | 
b[126]    | 0.3944    | 
b[127]    | 0.3194    | 
b[128]    | 0.25      | 
b[129]    | 0.4745    | 
b[130]    | 0.2642    | 
b[131]    | 0.451     | 
b[132]    | 0.1844    | 
b[133]    | 0.4054    | 
b[134]    | 0.3838    | 
b[135]    | 0.4864    | 
b[136]    | 0.3694    | 
b[137]    | 0.2502    | 
b[138]    | 0.3577    | 
b[139]    | 0.4723    | 
b[140]    | 0.4531    | 
b[141]    | 0.4826    | 
b[142]    | 0.4817    | 
b[143]    | 0.4721    | 
b[144]    | 0.3203    | 
b[145]    | 0.3819    | 
b[146]    | 0.3421    | 
b[147]    | 0.4327    | 
b[148]    | 0.5401    | 
b[149]    | 0.5109    | 
b[150]    | 0.3586    | 
b[151]    | 0.1106    | 
b[152]    | 0.2652    | 
b[153]    | 0.4232    | 
b[154]    | 0.3681    | 
b[155]    | 0.3033    | 
b[156]    | 0.2227    | 
b[157]    | 0.4141    | 
b[158]    | 0.3079    | 
b[159]    | 0.2746    | 
b[160]    | 0.2949    | 
b[161]    | 0.1182    | 
b[162]    | 0.5191    | 
b[163]    | 0.4058    | 
b[164]    | 0.3959    | 
b[165]    | 0.2824    | 
b[166]    | 0.3018    | 
b[167]    | 0.2823    | 
b[168]    | 0.2348    | 
b[169]    | 0.4943    | 
b[170]    | 0.3354    | 
b[171]    | 0.4766    | 
b[172]    | 0.3945    | 
b[173]    | 0.4539    | 
b[174]    | 0.4865    | 
b[175]    | 0.3601    | 
b[176]    | 0.2428    | 
b[177]    | 0.3026    | 
b[178]    | 0.3759    | 
b[179]    | 0.4839    | 
b[180]    | 0.5054    | 
b[181]    | 0.2982    | 
b[182]    | 0.0693    | 
b[183]    | 0.4691    | 
b[184]    | 0.4342    | 
b[185]    | 0.463     | 
b[186]    | 0.3229    | 
b[187]    | 0.3352    | 
b[188]    | 0.3841    | 
b[189]    | 0.2063    | 
b[190]    | 0.3857    | 
b[191]    | 0.4108    | 
b[192]    | 0.3878    | 
b[193]    | 0.3726    | 
b[194]    | 0.3711    | 
b[195]    | 0.2928    | 
b[196]    | 0.3867    | 
b[197]    | 0.4946    | 
b[198]    | 0.2883    | 
b[199]    | 0.3424    | 
b[200]    | 0.3095    | 
b[201]    | 0.4632    | 
b[202]    | 0.1853    | 
b[203]    | 0.2954    | 
b[204]    | 0.4221    | 
b[205]    | 0.3258    | 
b[206]    | 0.1637    | 
b[207]    | 0.295     | 
b[208]    | 0.4033    | 
b[209]    | 0.5309    | 
b[210]    | 0.3413    | 
b[211]    | 0.5499    | 
b[212]    | 0.3944    | 
b[213]    | 0.3382    | 
b[214]    | 0.0767    | 
b[215]    | 0.2105    | 
b[216]    | 0.4147    | 
b[217]    | 0.2271    | 
b[218]    | 0.4964    | 
b[219]    | 0.4928    | 
b[220]    | 0.4536    | 
b[221]    | 0.2446    | 
b[222]    | 0.3693    | 
b[223]    | 0.4184    | 
b[224]    | 0.0325    | 
b[225]    | 0.3901    | 
b[226]    | 0.5167    | 
b[227]    | 0.1514    | 
b[228]    | 0.4838    | 
b[229]    | 0.4739    | 
b[230]    | 0.5453    | 
b[231]    | 0.3911    | 
b[232]    | 0.2967    | 
b[233]    | 0.2323    | 
b[234]    | 0.3331    | 
b[235]    | 0.2772    | 
b[236]    | 0.393     | 
b[237]    | 0.2316    | 
b[238]    | 0.4346    | 
b[239]    | 0.4144    | 
b[240]    | 0.0273    | 
b[241]    | 0.3564    | 
b[242]    | 0.1549    | 
b[243]    | 0.3911    | 
b[244]    | 0.3772    | 
b[245]    | 0.4966    | 
b[246]    | 0.2265    | 
b[247]    | 0.2914    | 
b[248]    | 0.3436    | 
b[249]    | 0.3556    | 
b[250]    | 0.3919    | 
b[251]    | 0.2523    | 
b[252]    | 0.5187    | 
b[253]    | 0.3335    | 
b[254]    | 0.3598    | 
b[255]    | 0.3196    | 
b[256]    | 0.3402    | 
b[257]    | 0.2881    | 
b[258]    | 0.0343    | 
b[259]    | 0.3663    | 
b[260]    | 0.1794    | 
b[261]    | 0.4633    | 
b[262]    | 0.4071    | 
b[263]    | 0.2107    | 
b[264]    | 0.2653    | 
b[265]    | 0.1339    | 
b[266]    | 0.4538    | 
b[267]    | 0.3173    | 
b[268]    | 0.4993    | 
b[269]    | 0.2228    | 
b[270]    | 0.3785    | 
b[271]    | 0.1964    | 
b[272]    | 0.3434    | 
b[273]    | 0.3898    | 
b[274]    | 0.4361    | 
b[275]    | 0.285     | 
b[276]    | 0.1957    | 
b[277]    | 0.5187    | 
b[278]    | 0.254     | 
b[279]    | 0.2735    | 
b[280]    | 0.3727    | 
b[281]    | 0.3278    | 
b[282]    | 0.4894    | 
b[283]    | 0.4065    | 
b[284]    | 0.3606    | 
b[285]    | 0.3474    | 
b[286]    | 0.3498    | 
b[287]    | 0.1792    | 
b[288]    | 0.3301    | 
b[289]    | 0.4267    | 
b[290]    | 0.2115    | 
b[291]    | 0.4311    | 
b[292]    | 0.2347    | 
b[293]    | 0.4609    | 
b[294]    | 0.4348    | 
b[295]    | 0.3786    | 
b[296]    | 0.3167    | 
b[297]    | 0.2975    | 
b[298]    | 0.3148    | 
b[299]    | 0.3479    | 
b[300]    | 0.3756    | 
------------------------------------
Finished sucessfully.
MAP on training data: 0.6576
------------------------------------
MAP on test data: 0.4726

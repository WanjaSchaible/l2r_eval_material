
[+] General Parameters:
Training data:	/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/train_ps
Test data:	/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/test_ps
Feature vector representation: Dense.
Ranking method:	Random Forests
Feature description file:	Unspecified. All features will be used.
Train metric:	MAP
Test metric:	MAP
Feature normalization: No

[+] Random Forests's Parameters:
No. of bags: 300
Sub-sampling: 1.0
Feature-sampling: 0.3
No. of trees: 1
No. of leaves: 100
No. of threshold candidates: 256
Learning rate: 0.1


Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/train_ps]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/train_ps]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/train_ps]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/train_ps]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/train_ps]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/train_ps]... [Done.]            
(149 ranked lists, 44700 entries read)

Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/test_ps]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/test_ps]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/test_ps]: 0... 
Reading feature file [/data3/jschaible/BTC_l2r/EvalData/L2R_Evaluation/ldodds.com/foldsSAME/test_ps]... [Done.]            
(85 ranked lists, 25500 entries read)
Initializing... [Done]
------------------------------------
Training starts...
------------------------------------
bag       | MAP-B     | MAP-OOB     | 
------------------------------------
b[1]      | 0.5564    | 
b[2]      | 0.6322    | 
b[3]      | 0.6364    | 
b[4]      | 0.6227    | 
b[5]      | 0.6802    | 
b[6]      | 0.5692    | 
b[7]      | 0.5365    | 
b[8]      | 0.3343    | 
b[9]      | 0.3788    | 
b[10]     | 0.4508    | 
b[11]     | 0.1053    | 
b[12]     | 0.4099    | 
b[13]     | 0.7089    | 
b[14]     | 0.0405    | 
b[15]     | 0.628     | 
b[16]     | 0.6348    | 
b[17]     | 0.4661    | 
b[18]     | 0.3677    | 
b[19]     | 0.3688    | 
b[20]     | 0.5193    | 
b[21]     | 0.361     | 
b[22]     | 0.5237    | 
b[23]     | 0.3405    | 
b[24]     | 0.323     | 
b[25]     | 0.4805    | 
b[26]     | 0.5189    | 
b[27]     | 0.5873    | 
b[28]     | 0.1615    | 
b[29]     | 0.4449    | 
b[30]     | 0.5847    | 
b[31]     | 0.2093    | 
b[32]     | 0.6153    | 
b[33]     | 0.313     | 
b[34]     | 0.5653    | 
b[35]     | 0.4231    | 
b[36]     | 0.6709    | 
b[37]     | 0.4476    | 
b[38]     | 0.4507    | 
b[39]     | 0.508     | 
b[40]     | 0.5688    | 
b[41]     | 0.6458    | 
b[42]     | 0.537     | 
b[43]     | 0.4799    | 
b[44]     | 0.4879    | 
b[45]     | 0.391     | 
b[46]     | 0.6947    | 
b[47]     | 0.6019    | 
b[48]     | 0.393     | 
b[49]     | 0.6062    | 
b[50]     | 0.5422    | 
b[51]     | 0.6149    | 
b[52]     | 0.604     | 
b[53]     | 0.3191    | 
b[54]     | 0.6803    | 
b[55]     | 0.3343    | 
b[56]     | 0.5018    | 
b[57]     | 0.7026    | 
b[58]     | 0.298     | 
b[59]     | 0.4274    | 
b[60]     | 0.5611    | 
b[61]     | 0.0313    | 
b[62]     | 0.38      | 
b[63]     | 0.2166    | 
b[64]     | 0.6439    | 
b[65]     | 0.4897    | 
b[66]     | 0.6183    | 
b[67]     | 0.441     | 
b[68]     | 0.4505    | 
b[69]     | 0.5407    | 
b[70]     | 0.2835    | 
b[71]     | 0.1793    | 
b[72]     | 0.6969    | 
b[73]     | 0.6564    | 
b[74]     | 0.5551    | 
b[75]     | 0.4858    | 
b[76]     | 0.4584    | 
b[77]     | 0.4651    | 
b[78]     | 0.5798    | 
b[79]     | 0.4673    | 
b[80]     | 0.5482    | 
b[81]     | 0.5759    | 
b[82]     | 0.5755    | 
b[83]     | 0.5341    | 
b[84]     | 0.3862    | 
b[85]     | 0.6095    | 
b[86]     | 0.2649    | 
b[87]     | 0.2645    | 
b[88]     | 0.6082    | 
b[89]     | 0.4732    | 
b[90]     | 0.5277    | 
b[91]     | 0.3379    | 
b[92]     | 0.5099    | 
b[93]     | 0.5152    | 
b[94]     | 0.2451    | 
b[95]     | 0.367     | 
b[96]     | 0.5458    | 
b[97]     | 0.4699    | 
b[98]     | 0.5094    | 
b[99]     | 0.4547    | 
b[100]    | 0.6329    | 
b[101]    | 0.5579    | 
b[102]    | 0.4663    | 
b[103]    | 0.0652    | 
b[104]    | 0.5096    | 
b[105]    | 0.3468    | 
b[106]    | 0.562     | 
b[107]    | 0.4085    | 
b[108]    | 0.7096    | 
b[109]    | 0.2914    | 
b[110]    | 0.2531    | 
b[111]    | 0.4906    | 
b[112]    | 0.351     | 
b[113]    | 0.3611    | 
b[114]    | 0.6879    | 
b[115]    | 0.4952    | 
b[116]    | 0.5679    | 
b[117]    | 0.3996    | 
b[118]    | 0.5198    | 
b[119]    | 0.5599    | 
b[120]    | 0.2084    | 
b[121]    | 0.7377    | 
b[122]    | 0.5506    | 
b[123]    | 0.3136    | 
b[124]    | 0.1761    | 
b[125]    | 0.3146    | 
b[126]    | 0.1204    | 
b[127]    | 0.4952    | 
b[128]    | 0.5529    | 
b[129]    | 0.3245    | 
b[130]    | 0.252     | 
b[131]    | 0.311     | 
b[132]    | 0.5866    | 
b[133]    | 0.5623    | 
b[134]    | 0.1682    | 
b[135]    | 0.6918    | 
b[136]    | 0.5448    | 
b[137]    | 0.5321    | 
b[138]    | 0.6825    | 
b[139]    | 0.4829    | 
b[140]    | 0.2202    | 
b[141]    | 0.6668    | 
b[142]    | 0.4645    | 
b[143]    | 0.3132    | 
b[144]    | 0.6509    | 
b[145]    | 0.0346    | 
b[146]    | 0.4149    | 
b[147]    | 0.6278    | 
b[148]    | 0.2664    | 
b[149]    | 0.4217    | 
b[150]    | 0.5047    | 
b[151]    | 0.6578    | 
b[152]    | 0.0454    | 
b[153]    | 0.41      | 
b[154]    | 0.2808    | 
b[155]    | 0.6535    | 
b[156]    | 0.4707    | 
b[157]    | 0.7038    | 
b[158]    | 0.4969    | 
b[159]    | 0.3077    | 
b[160]    | 0.3773    | 
b[161]    | 0.7092    | 
b[162]    | 0.6554    | 
b[163]    | 0.5008    | 
b[164]    | 0.6526    | 
b[165]    | 0.2991    | 
b[166]    | 0.2545    | 
b[167]    | 0.704     | 
b[168]    | 0.6766    | 
b[169]    | 0.3869    | 
b[170]    | 0.6197    | 
b[171]    | 0.5028    | 
b[172]    | 0.6504    | 
b[173]    | 0.4939    | 
b[174]    | 0.5054    | 
b[175]    | 0.6019    | 
b[176]    | 0.38      | 
b[177]    | 0.1678    | 
b[178]    | 0.6221    | 
b[179]    | 0.58      | 
b[180]    | 0.3316    | 
b[181]    | 0.3819    | 
b[182]    | 0.4082    | 
b[183]    | 0.6546    | 
b[184]    | 0.553     | 
b[185]    | 0.394     | 
b[186]    | 0.3705    | 
b[187]    | 0.6999    | 
b[188]    | 0.6084    | 
b[189]    | 0.3026    | 
b[190]    | 0.6803    | 
b[191]    | 0.2298    | 
b[192]    | 0.217     | 
b[193]    | 0.6763    | 
b[194]    | 0.4107    | 
b[195]    | 0.6164    | 
b[196]    | 0.5201    | 
b[197]    | 0.4812    | 
b[198]    | 0.5357    | 
b[199]    | 0.4994    | 
b[200]    | 0.6586    | 
b[201]    | 0.5865    | 
b[202]    | 0.5454    | 
b[203]    | 0.6655    | 
b[204]    | 0.6029    | 
b[205]    | 0.5369    | 
b[206]    | 0.3416    | 
b[207]    | 0.4672    | 
b[208]    | 0.5937    | 
b[209]    | 0.3644    | 
b[210]    | 0.4859    | 
b[211]    | 0.6076    | 
b[212]    | 0.4467    | 
b[213]    | 0.4103    | 
b[214]    | 0.3342    | 
b[215]    | 0.3326    | 
b[216]    | 0.5969    | 
b[217]    | 0.5964    | 
b[218]    | 0.5669    | 
b[219]    | 0.3301    | 
b[220]    | 0.4662    | 
b[221]    | 0.5993    | 
b[222]    | 0.3965    | 
b[223]    | 0.4467    | 
b[224]    | 0.6078    | 
b[225]    | 0.305     | 
b[226]    | 0.7667    | 
b[227]    | 0.7555    | 
b[228]    | 0.4738    | 
b[229]    | 0.6445    | 
b[230]    | 0.5235    | 
b[231]    | 0.6452    | 
b[232]    | 0.7004    | 
b[233]    | 0.3705    | 
b[234]    | 0.6664    | 
b[235]    | 0.5542    | 
b[236]    | 0.6412    | 
b[237]    | 0.4657    | 
b[238]    | 0.6751    | 
b[239]    | 0.4634    | 
b[240]    | 0.4984    | 
b[241]    | 0.4314    | 
b[242]    | 0.6251    | 
b[243]    | 0.6242    | 
b[244]    | 0.6927    | 
b[245]    | 0.3392    | 
b[246]    | 0.6244    | 
b[247]    | 0.749     | 
b[248]    | 0.5882    | 
b[249]    | 0.5446    | 
b[250]    | 0.252     | 
b[251]    | 0.1985    | 
b[252]    | 0.4024    | 
b[253]    | 0.5392    | 
b[254]    | 0.599     | 
b[255]    | 0.7141    | 
b[256]    | 0.5119    | 
b[257]    | 0.4742    | 
b[258]    | 0.4413    | 
b[259]    | 0.5751    | 
b[260]    | 0.0803    | 
b[261]    | 0.5382    | 
b[262]    | 0.3805    | 
b[263]    | 0.5292    | 
b[264]    | 0.5172    | 
b[265]    | 0.6081    | 
b[266]    | 0.3536    | 
b[267]    | 0.6108    | 
b[268]    | 0.551     | 
b[269]    | 0.6021    | 
b[270]    | 0.6317    | 
b[271]    | 0.563     | 
b[272]    | 0.1933    | 
b[273]    | 0.7448    | 
b[274]    | 0.1276    | 
b[275]    | 0.2468    | 
b[276]    | 0.4163    | 
b[277]    | 0.5141    | 
b[278]    | 0.3787    | 
b[279]    | 0.6383    | 
b[280]    | 0.4114    | 
b[281]    | 0.4506    | 
b[282]    | 0.1514    | 
b[283]    | 0.2703    | 
b[284]    | 0.4388    | 
b[285]    | 0.5581    | 
b[286]    | 0.3155    | 
b[287]    | 0.2864    | 
b[288]    | 0.5122    | 
b[289]    | 0.4744    | 
b[290]    | 0.4858    | 
b[291]    | 0.5386    | 
b[292]    | 0.494     | 
b[293]    | 0.3071    | 
b[294]    | 0.4463    | 
b[295]    | 0.3849    | 
b[296]    | 0.7015    | 
b[297]    | 0.5424    | 
b[298]    | 0.6417    | 
b[299]    | 0.4599    | 
b[300]    | 0.4516    | 
------------------------------------
Finished sucessfully.
MAP on training data: 0.7374
------------------------------------
MAP on test data: 0.3812
